{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install realtimetts[gttsengine] pyttsx3 \n",
    "import requests\n",
    "import json\n",
    "from RealtimeTTS import TextToAudioStream, SystemEngine, GTTSEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printSameLine(str):\n",
    "    print(str, end=\"\", flush=True)\n",
    "\n",
    "def createMessage(content, isUser=True):\n",
    "    return {\n",
    "        'role': 'user' if isUser else 'assistant',\n",
    "        'content': content\n",
    "    }\n",
    "\n",
    "def sendMessage(endpoint, model, history, content, callback = None):\n",
    "    msg = createMessage(content)\n",
    "    history.append(msg)\n",
    "\n",
    "    req = requests.post(endpoint, json={\n",
    "        'model': model,\n",
    "        'messages': history,\n",
    "        'stream': True,\n",
    "    }, stream=True)\n",
    "\n",
    "    if req.status_code != 200:\n",
    "        raise Exception(f\"Failed to send message: {req.status_code} {req.reason}\")\n",
    "\n",
    "    req.raise_for_status()\n",
    "\n",
    "    total_msg = \"\"\n",
    "    for l in req.iter_lines():\n",
    "        res_json = json.loads(l)\n",
    "\n",
    "        if \"error\" in res_json: raise Exception(res_json.get('error'))\n",
    "        if res_json.get('done'): break\n",
    "\n",
    "        res_msg = res_json.get('message').get('content')\n",
    "        total_msg += res_msg\n",
    "\n",
    "        if callback is not None: callback(res_msg)\n",
    "\n",
    "    history.append(createMessage(total_msg, False))\n",
    "    return total_msg\n",
    "\n",
    "def makeTTSEngine(engine, stop_char_list = [\".\", \"!\", \"?\", \",\"]):\n",
    "    engine = TextToAudioStream(engine)\n",
    "\n",
    "    temp_sentence = \"\"\n",
    "    def callback(token):\n",
    "        nonlocal temp_sentence\n",
    "        temp_sentence += token\n",
    "        printSameLine(token)\n",
    "\n",
    "        if any([c in token for c in stop_char_list]):\n",
    "            engine.feed(temp_sentence)\n",
    "            if not engine.is_playing():\n",
    "                engine.play_async()\n",
    "            temp_sentence = \"\"\n",
    "            return\n",
    "\n",
    "    return callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm ready to chat. What's on your mind?\n",
      "Ready...\n"
     ]
    }
   ],
   "source": [
    "model = 'llama3'\n",
    "endpoint = 'http://localhost:11434/api/chat'\n",
    "history = []\n",
    "# tts_engine = makeTTSEngine(SystemEngine()) # offline (pyttsx3)\n",
    "tts_engine = makeTTSEngine(GTTSEngine())\n",
    "# can also use OpenAI voice service with their API\n",
    "\n",
    "def sendAndPlay(msg):\n",
    "    sendMessage(endpoint, model, history, msg, tts_engine)\n",
    "\n",
    "pre_prompt_condition = [\n",
    "    # 'your name is Nova',\n",
    "    'completely verbal conversation',\n",
    "    'short',\n",
    "    'professional but casual',\n",
    "]\n",
    "\n",
    "sendAndPlay(\"Condition for this conversation: \" + \", \".join(pre_prompt_condition))\n",
    "print(\"\\nReady...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to stop current playing voice\n",
    "# tts_engine.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a tough one! While opinions may vary, I think it's safe to say that a well-made classic vanilla or chocolate cake is hard to beat. But, if you're looking for something more unique, a good carrot cake with cream cheese frosting can't be ignored either! What's your go-to cake order?"
     ]
    }
   ],
   "source": [
    "sendAndPlay(\"Can you tell me what is the best cake?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
